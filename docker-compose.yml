# Docker Compose configuration for Superset, Airflow, and MCP services
services:
  # Main Postgres database for Superset
  postgres_main:
    image: postgres:17
    container_name: postgres_main
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${DATABASE_NAME}
    volumes:
      - postgres_volume_main:/var/lib/postgresql/data
    networks:
      - main_net
    ports:
      - "5432:5432"

  # Postgres database for Airflow
  postgres_airflow:
    image: postgres:17
    container_name: postgres_airflow
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: airflow_db
    volumes:
      - postgres_volume_airflow:/var/lib/postgresql/data
    networks:
      - main_net
    ports:
      - "5433:5432"

  # Superset main service
  superset_main:
    image: apache/superset:4.1.1
    container_name: superset_main
    restart: unless-stopped
    depends_on:
      - postgres_main
    environment:
      SUPERSET_SECRET_KEY: ${SUPERSET_SECRET_KEY}
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres_main:5432/${DATABASE_NAME}
      SUPERSET_WEBSERVER_BASEURL: ${SUPERSET_WEBSERVER_BASEURL}
      SUPERSET_ENABLE_MCP_SERVICE: "True"
      ENABLE_PROXY_FIX: "true"
      SUPERSET_APP_ROOT: "/"
    ports:
      - "8088:8088"
    networks:
      - main_net
    volumes:
      - superset_home:/app/superset_home
    command: bash -c "superset db upgrade && superset fab create-admin --username ${SUPERSET_USERNAME} --firstname Super --lastname User --email ${ADMIN_EMAIL} --password ${SUPERSET_ADMIN_PASSWORD} || true && superset init && gunicorn -w 4 -k sync --timeout 120 -b 0.0.0.0:8088 'superset.app:create_app()'"

  # Airflow main service
  airflow_main:
    image: apache/airflow:2.9.3
    container_name: airflow_main
    restart: unless-stopped
    depends_on:
      - postgres_airflow
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres_airflow:5432/airflow_db
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_WEBSERVER_SECRET_KEY}
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__WEBSERVER__BASE_URL: ${AIRFLOW__WEBSERVER__BASE_URL}
      AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX: "true"
    volumes:
      - airflow_dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - airflow_plugins:/opt/airflow/plugins
    ports:
      - "8081:8080"
    networks:
      - main_net
    command: bash -c "airflow db upgrade && airflow users create --username admin --firstname Admin --lastname User --role Admin --email ${ADMIN_EMAIL} --password ${AIRFLOW_ADMIN_PASSWORD} || true && airflow webserver & airflow scheduler"

# MCP server for Superset integration (base setup for hybrid Smithery)
  mcp_server:
    image: python:3.12-slim
    container_name: mcp_server
    restart: unless-stopped
    depends_on:
      - superset_main
    environment:
      SUPERSET_BASE_URL: ${SUPERSET_BASE_URL}
      SUPERSET_USERNAME: ${SUPERSET_USERNAME}
      SUPERSET_PASSWORD: ${SUPERSET_ADMIN_PASSWORD}
    ports:
      - "127.0.0.1:5008:5008"  # Bind to localhost for security
    networks:
      - main_net
    working_dir: /app/mcp
    volumes:
      - ./mcp_260925:/app/mcp       # local dev source
      - mcp_config:/app/config      # configs + .env persist
      - venv_data:/app/venv         # venv persist
      - node_modules:/root/.npm     # Node cache
    command: bash -c "apt-get update && apt-get install -y --no-install-recommends nodejs npm && if [ ! -d /app/venv/bin ]; then python3 -m venv /app/venv && . /app/venv/bin/activate && pip install --upgrade pip && pip install uv && uv pip install --system .; fi && echo -e 'SUPERSET_BASE_URL=${SUPERSET_BASE_URL}\nSUPERSET_USERNAME=${SUPERSET_USERNAME}\nSUPERSET_PASSWORD=$SUPERSET_ADMIN_PASSWORD' > /app/config/.env && tail -f /dev/null"

# BI Script Runner: a temporary solution for running ETL jobs without Airflow
  bi_script_runner:
    image: python:3.12-slim
    container_name: bi_script_runner
    restart: unless-stopped
    volumes:
      - /home/user/python_scripts/private_school_bi:/app
    working_dir: /app
    command: bash -c "apt-get update && apt-get install -y --no-install-recommends cron procps rsyslog && pip install --no-cache-dir --root-user-action=ignore -r requirements.txt && echo '0 1 * * * root cd /app && pip install --no-cache-dir --root-user-action=ignore -r requirements.txt >> /var/log/requirements_install.log 2>&1' > /etc/cron.d/bi_daily && echo '0 2 * * * root cd /app && /usr/local/bin/python /app/main.py >> /var/log/bi_script.log 2>&1' >> /etc/cron.d/bi_daily && chmod 0644 /etc/cron.d/bi_daily && chown root:root /etc/cron.d/bi_daily && mkdir -p /var/log && touch /var/log/bi_script.log /var/log/requirements_install.log && rsyslogd && cron -f & while [ ! -f /var/log/bi_script.log ]; do sleep 1; done; tail -f /var/log/bi_script.log"

# Volumes for persistent storage
volumes:
  postgres_volume_main:
  postgres_volume_airflow:
  superset_home:
  airflow_dags:
  airflow_logs:
  airflow_plugins:
  node_modules:  # New volume for Node.js storage
  mcp_config:    # Persists MCP server code and configs
  venv_data:     # Persists Python virtual environment

# Network configuration
networks:
  main_net:
    driver: bridge

